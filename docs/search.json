[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "",
    "text": "Abstract. This research project aims to measure the effects of monetary policy shocks on stock price volatility using the Bayesian Structural Vector Autoregressive Model in the Australian economy from 1990 to 2023.\nKeywords. Bayesian Structural VARs, Monetary policy shocks, Stock price volatility, Impulse response function"
  },
  {
    "objectID": "index.html#diagnostic-tests",
    "href": "index.html#diagnostic-tests",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "2.1 Diagnostic Tests",
    "text": "2.1 Diagnostic Tests\n\n2.1.1 Autocorrelation/Partial autocorrelation Function Plots\nThe autocorrelation test is used to identify the presence of serial correlation between a variable’s current value and its lagged value, indicating that past values influence the current value.\nThe autocorrelation function (ACF) plots in Figure 3 shows that all the variables except for stock price volatility have non-zero autocorrelation for at least 20 lags, implying that only stock price volatility is a stationary series and the other variables are highly persistent.\n\n\n\n\n\n\n\nFigure 3: Plots of autocorrelation functions\n\n\n\n\nThe partial autocorrelation function (PACF) plots in Figure 4 shows that the partial autocorrelation for all the variables are significant at the first lag. The partial autocorrelation for exchange rates is also significant at 2.\n\n\n\n\n\n\n\nFigure 4: Plots of partial autocorrelation functions\n\n\n\n\n\n\n2.1.2 Unit Root Test\n\nAugmented Dickey-Fuller Test\nThe augmented Dickey-Fuller test of the null hypothesis of unit root nonstationarity was performed to test the presence of the unit root.\nTable 3 shows that the null hypothesis was not rejected at the 1% significance level for all the variables except for stock price volatility, implying that all the variables except for stock price volatility are nonstationary series. Stock price volatility is the log of bipower variation and took logarithmic scale twice.\n\n\n\n\n\n\nVariable\nTest statistic\nCritical value\nStationarity\n\n\n\n\nGDP\n-1.284\n-3.99\nNo\n\n\nInterest rates\n-2.991\n-3.46\nNo\n\n\nConsumer price index\n-2.845\n-3.99\nNo\n\n\nExchange rates\n-2.181\n-3.46\nNo\n\n\nStock prices\n-3.186\n-3.99\nNo\n\n\nStock price volatility\n-4.543\n-3.46\nYes\n\n\n\n\n\nTable 3: Augmented Dickey-Fuller test results\n\n\n\nTable 4 shows that the Augmented Dickey-Fuller test results on the first difference of the variables. We find that all the variables are unit root stationary at the 1% significance level, and conclude that all the variables except for stock price volatility are integrated of order one, \\(I(1)\\). Stock price volatility is stationary series and integrated of order zero, \\(I(0)\\).\n\n\n\n\n\n\nVariable\nTest statistic\nCritical value\nStationarity\n\n\n\n\nGDP\n-5.225\n-3.46\nYes\n\n\nInterest rates\n-5.574\n-2.58\nYes\n\n\nConsumer price index\n-6.089\n-3.46\nYes\n\n\nExchange rates\n-7.589\n-2.58\nYes\n\n\nStock prices\n-6.905\n-3.46\nYes\n\n\nStock price volatility\n-8.322\n-2.58\nYes\n\n\n\n\n\nTable 4: Augmented Dickey-Fuller test results on the first difference"
  },
  {
    "objectID": "index.html#model-specification",
    "href": "index.html#model-specification",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.1 Model Specification",
    "text": "3.1 Model Specification\nThis study uses a Bayesian Structural vector autoregression model to measure the dynamic and contemporaneous relationships between variables. The endogenous variables in the model are the following: \\[\nY_t=\n\\begin{bmatrix}\n   gdp_t \\\\ICR_t \\\\cpi_t \\\\EXR_t \\\\stp_t \\\\vol_t\n\\end{bmatrix}\n\\] \\(Y_t\\) contains six variables ordered as\n   (1) Real GDP, \\(gdp_t\\),\n   (2) Interest rates, \\(ICR_t\\),\n   (3) Consumer price index, \\(cpi_t\\),\n   (4) Exchange rates from AUD to USD, \\(EXR_t\\),\n   (5) Stock prices, \\(stp_t\\), and\n   (6) Stock price volatility, \\(vol_t\\).\n\nStructural Form\nThe Structural form model can be represented as follows: \\[\n\\begin{gather}\nB_0y_t = b_0 + \\sum_{i=1}^{p} B_iy_{t-i} + u_t\n\\\\ u_t|Y_{t-1} \\sim _{iid} \\mathcal{N}(0_N, I_N)\n\\end{gather}\n\\] where\n   \\(y_t\\) is an \\(N \\times 1\\) vector of endogenous variables at time \\(t\\),\n   \\(B_0\\) is an \\(N \\times N\\) structural matrix that captures contemporaneous relationships between variables,\n   \\(u_t\\) is an \\(N \\times 1\\) vector conditionally on \\(Y_{t-1}\\) orthogonal or independent structural shocks,\n   \\(N\\) is the number of endogeneous variables, and \\(p\\) is the lag order.\n To obtain a model in a form that uses the autoregressive parameters of the VAR model, we can premultiply the SVAR equation by \\(B_0^{-1}\\) and get: \\[\n\\begin{align}\ny_t &= B_0^{-1}b_0 + \\sum_{i=1}^{p}B_0^{-1}B_{i}y_{t-i} + B_0^{-1}u_t\n\\end{align}\n\\] It can be rewritten as follows: \\[\n\\begin{align}\ny_t &= \\mu_0 + \\sum_{i=1}^{p}A_iy_{t-i} + Bu_t \\\\\n\\\\ &u_t|Y_{t-1} \\sim _{iid} \\mathcal{N}(0_N, I_N)\n\\end{align}\n\\] where\n   \\(B = B_0^{-1}\\) is a contemporaneous effect matrix that captures contemporaneous effects of shocks on variables \\(y_t\\),\n   \\(A_i = B_0^{-1}B_i\\) is autoregressive slope coefficients, and\n   \\(\\mu_0 = B_0^{-1}b_0\\) is a constant term.\n\n\nReduced Form\nThrough the equivalence transformations, the Structural form model can be represented as the reduced form model as follows: \\[\n\\begin{gather}\ny_t = \\mu_0 + \\sum_{i=1}^{p} A_iy_{t-i} + \\epsilon_t \\\\\n\\epsilon_t|Y_{t-1} \\sim _{iid} \\mathcal{N}(0_N, \\Sigma)\n\\end{gather}\n\\] where\n   \\(Y_t\\) is an \\(N \\times 1\\) vector of endogenous variables at time \\(t\\),\n   \\(A_i\\) is an \\(N \\times N\\) matrix of autoregressive slope parameters,\n   \\(\\mu_0\\) is an \\(N \\times 1\\) vector of constant terms,\n   \\(\\epsilon_t\\) is an \\(N \\times 1\\) vector of the multivariate white noise error terms, where \\(\\epsilon_t = Bu_t\\),\n   \\(\\Sigma\\) is an \\(N \\times N\\) covariance matrix of the error terms \\(\\epsilon_t\\), where \\(\\Sigma = B_0^{-1} {B_0^{-1}}'\\),\n   \\(N\\) is the number of endogeneous variables, and \\(p\\) is the lag order.\n The reduced form can be represented in a matrix form as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim \\mathcal{MN}_{T \\times N}(0_{T \\times N},\\Sigma_{N \\times N},I_T)\n\\end{gather}\n\\]  \\[\n\\begin{align}\nY = \\begin{bmatrix} y_{1}' \\\\y_{2}'  \\\\. \\\\. \\\\. \\\\y_{T}' \\end{bmatrix}_{T \\times N} \\quad\nA = \\begin{bmatrix}\\mu_{0}' \\\\A_{1}' \\\\.\\\\.\\\\.\\\\A_{p}' \\end{bmatrix}_{K \\times N} \\quad\nx_t =\\begin{bmatrix}\\ 1 \\\\y_{t-1} \\\\.\\\\.\\\\.\\\\y_{t-p} \\end{bmatrix}_{K \\times 1} \\quad\nX = \\begin{bmatrix}\\ x_{1}' \\\\x_{2}' \\\\.\\\\.\\\\.\\\\x_{T}' \\end{bmatrix}_{T \\times K} \\quad\nE = \\begin{bmatrix}\\ \\epsilon _{1}'  \\\\\\epsilon _{2}' \\\\.\\\\.\\\\.\\\\\\epsilon _{T}' \\end{bmatrix}_{T \\times N}\n\\end{align}\n\\] where\n   \\(Y\\) is a \\(T \\times N\\) matrix of endogenous variables at time \\(T\\),\n   \\(A\\) is a \\(K \\times N\\) matrix of autoregressive slope parameters,\n   \\(X\\) is a \\(T \\times N\\) matrix of covariates,\n   \\(E\\) is a \\(T \\times N\\) matrix of the white noise error terms,\n   \\(\\Sigma\\) is an \\(N \\times N\\) row-specific covariance matrix of error terms\n   \\(I_T\\) is an \\(T \\times T\\) identity matrix representing the column-specific covariance matrix of error,\n   \\(N\\) is the number of endogeneous variables,\n   \\(T\\) is the number of time periods,\n   \\(p\\) is the lag order, and \\(K = 1 + pN\\)."
  },
  {
    "objectID": "index.html#bayes-theorem",
    "href": "index.html#bayes-theorem",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.2 Bayes’ theorem",
    "text": "3.2 Bayes’ theorem\nFor parameter estimation, the Bayes’ theorem is used to derive the joint posterior distribution.\nThe joint posterior distribution of \\(A\\) and \\(\\Sigma\\) can be estimated as follows: \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\]"
  },
  {
    "objectID": "index.html#minnesota-prior",
    "href": "index.html#minnesota-prior",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.3 Minnesota Prior",
    "text": "3.3 Minnesota Prior\nThe Minnesota prior is a type of prior distribution that assumes that the variables are assumed to follow a random walk process. It imposes restrictions on the coefficients of the model by shrinking the coefficients on the lag of other variables more aggressively compared to the coefficients of their own lags, reflecting that a variable’s past values are more important predictors of its current value. The impact of past values on future values diminishes as lag p increases.\nUsing the Minnesota prior, we set the prior mean \\(\\underline{A}\\) as the following: \\[\n\\begin{align}\n\\underline{A} = \\begin{bmatrix} \\mathbf{0}_{N \\times 1} \\\\ I_N \\\\ \\mathbf{0}_{N \\times (p-1)N} \\end{bmatrix}\n\\end{align}\n\\] where the prior covariance matrix is \\[\n\\begin{align}\nVar[vec(A)] &= \\Sigma \\otimes  \\underline{V}\n\\end{align}\n\\] Column-specific prior covariance of \\(A\\) is defined as the following: \\[\n\\begin{align}\n\\underline{V} &= \\text{diag}([\\kappa_2 \\quad \\kappa_1 (\\mathbf{p}^{-2} \\otimes \\imath'_N)])\n\\end{align}\n\\] where \\[\n\\begin{align}\n\\mathbf{p} = [1,2, ..., p]\n\\\\ \\imath_N = [1,...,1]\n\\end{align}\n\\]\n   \\(\\kappa_1\\) is overall shrinkage level of autoregressive slopes, and\n   \\(\\kappa_2\\) is overall shrinkage of the constant term.\n Two shrinkage hyperparameters \\(\\kappa_1\\) and \\(\\kappa_2\\) controls the level of shrinkage/dispersion of the prior distribution around the prior mean \\(\\underline{A}\\)."
  },
  {
    "objectID": "index.html#identification",
    "href": "index.html#identification",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.4 Identification",
    "text": "3.4 Identification\nSign restrictions are imposed to obtain the identification of the system, namely orthogonal shocks \\(u_t\\) and matrix \\(B_0\\). \\[\n\\begin{align}\ny_t &= \\mu_0 + \\sum_{i=1}^{p}A_iy_{t-i} + Bu_t \\\\\n\\\\ &u_t|Y_{t-1} \\sim _{iid} \\mathcal{N}(0_N, I_N)\n\\end{align}\n\\] \\(B\\) = \\(B_0^{-1}\\) is a contemporaneous effect matrix that captures contemporaneous effects of shocks on variables \\(y_t\\)\nFor each sample draws from the posterior distribution of \\(A\\), \\(\\Sigma\\) from the reduced form, the contemporaneous effects matrix is derived as: \\[\n\\tilde{B}=\\tilde{B}^{-1}_0=\\text{chol}(\\Sigma)\n\\] Contemporaneous effects matrix \\(B\\) is identified by searching for an appropriate rotation matrix \\(Q\\) such that prescribed sign restrictions hold: \\[\nB = Q\\tilde{B}\n\\] such that:\nFor \\(n\\) = 1, … , \\(N\\) check if \\[\n\\textbf{R}_nf(\\tilde{B}_0,\\tilde{B}_+)e_n\\ &gt; \\textbf{0}_{R \\times 1}\n\\] f (B+, B0) – \\(R \\times N\\) matrix of functions of parameters to be restricted, f (B+, B0) = \\(B_0'\\) – restrictions on contemporaneous relationships f (B+, B0) = B 1 0\\(B_1'\\) – restrictions on contemporaneous effects\n\\[\n\\begin{gather}\nf(\\tilde{B}_0,\\tilde{B}_+) =\n\\begin{bmatrix}\n\\Theta_0 \\space \\Theta_1\n\\end{bmatrix}\n= B =  \\tilde{B}^{-1}_0\n\\end{gather}\n\\]\nTable 5 shows the sign restrictions for the positive monetary policy shock.\n\n\n\n\n\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\nMonetary Policy Shock\n-\n+\n-\n+\n\n\n\n\n\n\n\nTable 5: Sign restrictions\n\n\n\nThe following sign restrictions are imposed on on the variable interest rates. \\[\nf(B_0,B_+)=\\Theta_0=B=\n\\begin{bmatrix}\n* & - & * & * & * & * \\\\\n* & + & * & * & * & * \\\\\n* & - & * & * & * & * \\\\\n* & + & * & * & * & * \\\\\n* & * & * & * & * & * \\\\\n* & * & * & * & * & * \\\\\n\\end{bmatrix}\n\\] The restriction matrix R is as follows: \\[\n\\textbf{R}_2=\\begin{bmatrix}\n-1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & -1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "index.html#impulse-response-function",
    "href": "index.html#impulse-response-function",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.5 Impulse Response Function",
    "text": "3.5 Impulse Response Function\nImpulse response functions to orthogonal shocks capture the dynamic causal effects of an exogenous shock on the endogenous variables in the model. To obtain the impulse response function from the reduced form \\(VAR(p)\\) model, a stationary Vector \\(VAR(p)\\) process should be rewritted in \\(VMA(\\infty)\\) form. The \\(VAR(1)\\) representation of the reduced form \\(VAR(p)\\) model is the following: \\[\n\\begin{align}\nY_t &= \\textbf{A}Y_{t-1}+E_t\n\\\\ &= E_t+\\textbf{A}E_{t-1}+\\textbf{A}^2E_{t-2}+ ...\n\\end{align}\n\\] Using the \\(J\\) matrix, transform a \\(VAR(1)\\) representation back to a \\(VAR(p)\\) representation. \\[\nJ=\\big[I_N\\quad 0_{N\\times N(p-1)}\\big]\n\\] Then, \\[\n\\begin{align}\ny_t &= JY_t\n\\\\ &=JE_t+J\\textbf{A}J'JE_{t-1}+J\\textbf{A}^2J'JE_{t-2}+...\n\\\\ &=\\epsilon_t+J\\textbf{A}J'\\varepsilon_{t-1}+J\\textbf{A}^2J'\\varepsilon_{t-2}+...\n\\end{align}\n\\] Substitute \\(\\epsilon_t\\) to \\(Bu_t\\): \\[\n\\begin{align}\ny_t &=Bu_t+J\\textbf{A}J'Bu_{t-1}+J\\textbf{A}^2J'Bu_{t-2}+...\n\\\\ &=\\Theta_0u_t+\\Theta_1u_{t-1}+\\Theta_2u_{t-2}+...\n\\end{align}\n\\] Differenciate to obtain matrices \\(\\Theta_i\\): \\[\n\\begin{align}\n\\frac{\\partial y_{t+i}}{\\partial u_t} = \\Theta_i = J\\textbf{A}^iJ'B\n\\end{align}\n\\] where matrices \\(\\Theta_i\\) identify the impulse response functions, which represent responses of all variables in \\(Y_t\\) to orthogonal shocks, \\(i\\) periods after shock’s occurence."
  },
  {
    "objectID": "index.html#standard-bayesian-svar-model",
    "href": "index.html#standard-bayesian-svar-model",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.1 Standard Bayesian SVAR Model",
    "text": "4.1 Standard Bayesian SVAR Model\n\n4.1.1 Model Specification\nThe reduced form representation in a matrix form is as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim \\mathcal{MN}_{T \\times N}(0_{T \\times N},\\Sigma,I_T) \\\\\n\\end{gather}\n\\]\n\n\n4.1.2 Estimation Procedure\nFor estimation, the Bayes’ theorem is used to derive the joint posterior distribution for \\(A\\) and \\(\\Sigma\\). \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\] The model specification implies the following form for the kernel of the likelihood function: \\[\n\\begin{align}\nL(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\}\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\}\n\\end{align}\n\\] where \\[\n\\begin{align}\n\\hat{A} &= (X'X)^{-1}X'Y\n\\\\ \\hat{\\Sigma} &= \\frac{1}{T} (Y-X \\hat{A})'(Y-X \\hat{A})\n\\end{align}\n\\] are from the maximum likelihood estimation.\nThe natural-conjugate prior distribution where \\(A\\) is matrix normal and \\(\\Sigma\\) follows inverse Wishart distribution has the same form as the joint posterior distribution for \\(A\\) and \\(\\Sigma\\). \\[\n\\begin{gather}\np(A,\\Sigma) = p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ A|\\Sigma \\sim \\mathcal{MN}_{K \\times N}(\\underline{A},\\Sigma,\\underline{V})\n\\\\ \\Sigma \\sim \\mathcal{IW}_N(\\underline{S},\\underline{\\nu})\n\\end{gather}\n\\] This implies the following form for the kernel of the natural-conjugate prior distribution: \\[\n\\begin{align}\np(A,\\Sigma) &= p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2}tr \\left[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A}) \\right] \\right\\}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2}tr \\left[\\Sigma^{-1}\\underline{S} \\right] \\right\\}\n\\end{align}\n\\]\nThe conditional posterior distribution is given by the product of the likelihood function and the prior distribution. \\[\n\\begin{align}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X) \\cdot p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\}\n\\\\ &\\quad\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\}\n\\\\ &\\quad\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1} \\left[(A-\\hat{A})'X'X(A-\\hat{A})+(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})+(Y-X\\hat{A})'(Y-X\\hat{A})+\\underline{S} \\right] \\right] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{ -\\frac{1}{2} tr \\left[\\Sigma^{-1}\\left[(A-\\overline{A})'\\overline{V}^{-1} (A-\\overline{A})+\\underline{S}+Y'Y+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A}'\\overline{V}^{-1} \\overline{A} \\right] \\right] \\right\\}\n\\end{align}\n\\] Combining the terms yields the following the joint posterior distributions for \\(A\\) and \\(\\Sigma\\): \\[\n\\begin{gather}\np(A,\\Sigma|Y,X) = p(A|Y,X,\\Sigma) \\cdot p(\\Sigma|Y,X) = \\mathcal{MNIW}_{K \\times N}(\\overline{A}, \\overline{V}, \\overline{S}, \\overline{\\nu}) \\\\\n\\\\ p(A|Y,X,\\Sigma) = \\mathcal{MN}_{K \\times N}(\\overline{A}, \\Sigma, \\overline{V}) \\\\\n\\\\ p(\\Sigma|Y,X) = \\mathcal{IW}_N(\\overline{S},\\overline{\\nu}) \\\\\n\\end{gather}\n\\] where the parameters of the joint posterior distribution are the following: \\[\n\\begin{align}\n\\overline{V} &= (X'X + \\underline{V}^{-1})^{-1}\n\\\\ \\overline{A} &= \\overline{V}(X'Y + \\underline{V}^{-1}\\underline{A})\n\\\\ \\overline{S} &= \\underline{S} + Y'Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A}\n\\\\ \\overline{\\nu} &= T + \\underline{\\nu}\n\\end{align}\n\\]\n\n\n4.1.3 Algorithm Validation\nTo check the validity of the algorithms, two independent bi-variate Gaussian random walk processes with 1,000 observations were generated to simulate unit-root non-stationary macroeconomic variables.\nThe bi-variate Gaussian random walk process is represented as follows: \\[\ny_t =\n\\begin{bmatrix} y_{t,1} \\\\ y_{t,2} \\end{bmatrix}\n= \\begin{bmatrix} y_{t-1,1} \\\\ y_{t-1,2} \\end{bmatrix}\n+ \\begin{bmatrix} \\epsilon_{t,1} \\\\ \\epsilon_{t,2} \\end{bmatrix}\n\\] where both \\(\\epsilon_{t,1}\\) and \\(\\epsilon_{t,2}\\) have mean of zero and variance of one. \\[\n\\begin{align}\n\\epsilon_{t,1} \\sim \\mathcal{N}(0,1)\n\\\\ \\epsilon_{t,2} \\sim \\mathcal{N}(0,1)\n\\end{align}\n\\]\nThe plot below shows the bi-variate Gaussian random walk process.\n\n\n\n\n\n\n\n\nGibbs Sampler\nUsing the parameter of the joint posterior distribution \\(\\overline{A}\\), \\(\\overline{V}\\),\\(\\overline{S}\\), \\(\\overline{\\nu}\\) computed in the section 4.1.2, we obtain a sample of \\(S\\) draws from the posterior distribution.\nAt each iteration \\(s\\) where \\(s\\) goes from 1 to \\(S\\),\n\nDraw \\(\\Sigma^{(s)} \\sim P(\\Sigma|Y,X)\\) from the \\(\\mathcal{IW}_N(\\overline{S},\\overline{\\nu})\\) distribution.\nDraw \\(A^{(s)} \\sim P(A|Y,X,\\Sigma^{(s)})\\) from the \\(\\mathcal{MN}_{K \\times N}(\\overline{A},\\Sigma^{(s)}, \\overline{V})\\) distribution using the draw \\(\\Sigma^{(s)}\\).\n\nOutput is the sample draws from the joint posterior distribution \\(\\left\\{ {A^{(s)}, \\Sigma^{(s)}}\\right\\}^{S}_{s=1}\\).\nThe prior.distribution function below computes prior distribution.\n\n\nSee R code\nprior.distribution &lt;- function(N, p) {\n  \n  # Prior distribution\n  ############################################################\n  # Calculate the MLE\n  # ----------------------------------------------------------\n  A.hat       &lt;- solve(t(X)%*%X)%*%t(X)%*%Y                \n  Sigma.hat   &lt;- t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)  \n  \n  # Specify the prior distribution parameters\n  # ----------------------------------------------------------\n  kappa.1     &lt;- 1\n  kappa.2     &lt;- 100\n  \n  A.prior     &lt;- matrix(0, nrow(A.hat), ncol(A.hat))\n  A.prior[2:(N+1),] &lt;- diag(N)\n  V.prior     &lt;- diag(c(kappa.2, kappa.1*((1:p)^(-2))%x%rep(1,N)))\n  S.prior     &lt;- diag(diag(Sigma.hat))\n  nu.prior    &lt;- N+1  \n\n  return (list(A.prior = A.prior,\n               V.prior = V.prior,\n               S.prior = S.prior,\n               nu.prior = nu.prior))\n}\n\n\nThe function baseline.posterior below computes posterior distribution of the standard model.\n\n\nSee R code\nbaseline.posterior &lt;- function(X, Y, N, p, S, prior.distribution) {\n  \n  A.prior  &lt;- prior.distribution$A.prior\n  V.prior  &lt;- prior.distribution$V.prior\n  S.prior  &lt;- prior.distribution$S.prior\n  nu.prior &lt;- prior.distribution$nu.prior\n\n  # Posterior distribution\n  ############################################################\n  # Specify the matrix normal-inverse Wishart posterior parameters\n  # ----------------------------------------------------------\n  V.bar.inv   &lt;- t(X)%*%X + diag(1/diag(V.prior))\n  V.bar       &lt;- solve(V.bar.inv)\n  A.bar       &lt;- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar      &lt;- nrow(Y) + nu.prior\n  S.bar       &lt;- S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv   &lt;- solve(S.bar)\n  \n  # Draw Posterior distribution\n  # ----------------------------------------------------------\n  ## Draw from the Reduced Form\n  ### Draw Sigma from the inverse Wishart distribution\n  Sigma.posterior   &lt;- rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   &lt;- apply(Sigma.posterior, 3, solve)  \n  \n  # Initialise arrays to store posterior draws\n  Sigma.posterior   &lt;- array(Sigma.posterior, c(N,N,S))\n  A.posterior       &lt;- array(rnorm(prod(c(dim(A.bar), S))), c(dim(A.bar), S)) \n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    \n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s        &lt;- chol(Sigma.posterior[,,s])\n    L                  &lt;- t(chol(V.bar))\n    B0.posterior[,,s]  &lt;- solve(t(cholSigma.s)) \n    A.posterior[,,s]   &lt;- A.bar + L%*%A.posterior[,,s]%*%cholSigma.s\n    \n    ### Draw Bplus\n    B1.posterior[,,s]  &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n    }\n    \n  return(list(B0.posterior = B0.posterior, \n              B1.posterior = B1.posterior,\n              A.posterior = A.posterior, \n              Sigma.posterior = Sigma.posterior))\n}\n\n\nThe RW.identification function below imposes sign restrictions on the random walk process.\n\n\nSee R code\nRW.identification &lt;- function (N, p, sign.restrictions, posterior.distribution){\n  \n  A.posterior &lt;- posterior.distribution$A.posterior\n  Sigma.posterior &lt;- posterior.distribution$Sigma.posterior\n  B0.posterior &lt;- posterior.distribution$B0.posterior\n  B1.posterior &lt;- posterior.distribution$B1.posterior\n  \n  S &lt;- dim(A.posterior)[3]\n  \n  # Identification via sign restrictions\n  ############################################################\n  # Initialise arrays to store Q identified estimates\n  i.vec &lt;- c()\n  Q.store      &lt;- array(NA, c(N,N,S))\n  B0.store     &lt;- array(NA, c(N,N,S))\n  B1.store     &lt;- array(NA, c(N,K,S))\n  \n  # Generate corresponding R matrix\n  R &lt;- diag(sign.restrictions)\n  \n  for (s in 1:S){\n    B0.tilde      &lt;- B0.posterior[,,s]\n    B1.tilde      &lt;- B1.posterior[,,s]\n    \n    sign.restrictions.do.not.hold = TRUE\n    i=1\n    while (sign.restrictions.do.not.hold){\n      X           &lt;- matrix(rnorm(N*N), N, N)         \n      QR          &lt;- qr(X, tol=1e-10)\n      Q           &lt;- qr.Q(QR, complete=TRUE)\n      R           &lt;- qr.R(QR, complete=TRUE)\n      Q           &lt;- t(Q%*%diag(sign(diag(R))))\n      B0          &lt;- Q%*%B0.tilde                    \n      B1          &lt;- Q%*%B1.tilde                   \n      B0.inv      &lt;- solve(B0)      \n      check       &lt;- all(B0[1,1]&gt;0, B0[2,2]&gt;0)\n      \n      if (check){sign.restrictions.do.not.hold = FALSE}\n      i=i+1\n      }\n    \n    i.vec &lt;- c(i.vec, i) \n    Q.store[,,s]   &lt;- Q\n    B0.store[,,s]  &lt;- B0\n    B1.store[,,s]  &lt;- B1\n    }\n  \n  B0.mean     &lt;- apply(B0.store, 1:2, mean)  \n  B1.mean     &lt;- apply(B1.store, 1:2, mean)\n  \n  return(list(B0.mean = B0.mean, \n              B1.mean = B1.mean))\n  }\n\n\nThe results below show the mean of the matrices \\(B_0\\) and \\(B_+\\).\n\n\nMean of the \\(B_0\\) Matrix\n\n\n0.6396\n-0.0220\n\n\n0.0402\n0.6468\n\n\n\n\n\n\nMean of the \\(B_+\\) Matrix\n\n\n0.0354\n0.6353\n-0.0211\n\n\n0.0148\n0.0448\n0.6432\n\n\n\n\nThe results below show the mean of the matrices \\(A\\) and \\(\\Sigma\\).\n\n\n\nMean of the \\(A\\) posterior\n\n\n\ny1\ny2\n\n\n\n\nconstant\n0.0549\n0.0176\n\n\nlag of y1\n0.9937\n0.0076\n\n\nlag of y2\n0.0010\n0.9944\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\n\ny1\ny2\n\n\n\n\ny1\n0.9635\n-0.0115\n\n\ny2\n-0.0115\n0.9413"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-errors",
    "href": "index.html#bayesian-svar-model-with-t-distributed-errors",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.2 Bayesian SVAR Model with t-distributed Errors",
    "text": "4.2 Bayesian SVAR Model with t-distributed Errors\n\n4.2.1 Model Specification\nTo relax the normality assumption in the error terms, we assumed error terms to be t-distributed. The stock price is responsive to unanticipated events, which causes fluctuation in price and volatility. The large gains and losses observed in stocks can be addressed in leptokurtic distribution, and t-distribution is a good candidate for our model of stock price volatility.\nThe reduced form representation in a matrix form is as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X, \\lambda \\sim \\mathcal{MN}_{T \\times N}(0_{T \\times N},\\Sigma,\\lambda I_T)\n\\end{gather}\n\\] where the column-specific covariance matrix of error terms is set to be \\(\\lambda I_T\\).\nThe parameter lambda is inverse gamma 2 distributed with scale parameter \\(s_{\\lambda}\\) and shape parameter \\(\\nu_{\\lambda}\\). We assume fixed numbers for \\(s_{\\lambda}\\) and \\(\\nu_{\\lambda}\\) in this study. \\[\n\\lambda \\sim \\mathcal{IG}2(s_{\\lambda}, \\nu_{\\lambda})\n\\] Then it follows multivariate t-distribution: \\[\n\\begin{gather}\nE|X \\sim t_N(0, \\Sigma,\\nu)\n\\end{gather}\n\\]\n\n\n4.2.2 Estimation Procedure\nUsing the Bayes’ theorem, the joint posterior distribution for \\(A\\) and \\(\\Sigma\\) is the following: \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X,\\lambda)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X,\\lambda)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\] The kernel of the likelihood function follows as: \\[\n\\begin{align}\nL(A,\\Sigma|Y,X,\\lambda) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} \\text{tr} \\left[\\Sigma^{-1}(Y-XA)'(\\lambda I_T)^{-1}(Y-XA) \\right] \\right\\}\n\\end{align}\n\\] The natural-conjugate prior distribution where \\(A\\) follows matrix normal, \\(\\Sigma\\) follows inverse Wishart and \\(\\lambda\\) follows inverse gamma 2 distribution, have the same form as the joint posterior distribution for \\(A\\), \\(\\Sigma\\), and \\(\\lambda\\). \\[\n\\begin{gather}\np(A,\\Sigma, \\lambda) = p(A|\\Sigma) \\cdot p(\\Sigma) \\cdot p(\\lambda)\\\\\n\\\\ A|\\Sigma \\sim \\mathcal{MN}_{K \\times N}(\\underline{A},\\Sigma,\\underline{V})\n\\\\ \\Sigma \\sim \\mathcal{IW}_N(\\underline{S},\\underline{\\nu})\n\\\\ \\lambda \\sim \\mathcal{IG}2(\\underline{s_{\\lambda}}, \\underline{\\nu_{\\lambda}})\n\\end{gather}\n\\] This implies the following form for the kernel of the natural-conjugate prior distribution: \\[\n\\begin{align}\np(A,\\Sigma, \\lambda) &= p(A|\\Sigma) \\cdot p(\\Sigma) \\cdot p(\\lambda) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp \\left\\{ -\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n&\\quad\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\}\n\\end{align}\n\\] The conditional posterior distribution of \\(A\\) and \\(\\Sigma\\) is given by the product of the likelihood function and the prior distribution: \\[\n\\begin{align}\np(A,\\Sigma|Y,X,\\lambda) &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA) ] \\right\\}\n\\\\ &\\quad\\times\n\\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp \\left\\{ -\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda I_T)^{-1}Y - 2A'X'(\\lambda I_T)^{-1}Y + A'X'(\\lambda I_T)^{-1}XA + A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})] \\right\\}\n\\end{align}\n\\] Then, the joint posterior distribution of \\(A\\) and \\(\\Sigma\\) is derived as: \\[\n\\begin{gather}\np(A,\\Sigma|Y,X,\\lambda) = p(A|Y,X,\\Sigma, \\lambda) \\cdot p(\\Sigma|Y,X,\\lambda) = \\mathcal{MNIW}_{K \\times N}(\\overline{A}, \\overline{V}, \\overline{S}, \\overline{\\nu}) \\\\\n\\\\ p(A|Y,X,\\Sigma,\\lambda) = \\mathcal{MN}_{K \\times N}(\\overline{A}, \\Sigma, \\overline{V}) \\\\\n\\\\ p(\\Sigma|Y,X,\\lambda) = \\mathcal{IW}_N(\\overline{S},\\overline{\\nu}) \\\\\n\\end{gather}\n\\] where the parameters of the joint posterior distribution are the following: \\[\n\\begin{align}\n\\overline{V} &= [X'(\\lambda I_T)^{-1}X + \\underline{V}^{-1}]^{-1} \\\\\n\\overline{A} &= \\overline{V}[X'(\\lambda I_T)^{-1}Y + \\underline{V}^{-1}\\underline{A}] \\\\\n\\overline{S} &= Y'(\\lambda I_T)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A} + \\underline{S} \\\\\n\\overline{\\nu} &= \\underline{\\nu} + T\n\\end{align}\n\\] The conditional posterior distribution of \\(\\lambda\\) is derived as follows: \\[\n\\begin{align}\np(\\lambda|Y,X,A,\\Sigma) &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(\\lambda) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA)] \\right\\}\n\\\\ &\\quad\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(I_T)^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] \\right\\} \\\\\n&\\quad\\times \\lambda^{-\\frac{TN}{2}} \\cdot \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(I_T)^{-\\frac{N}{2}} \\cdot \\lambda^{-\\frac{TN+\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} [tr(\\Sigma^{-1}(Y-XA)'(Y-XA)) + \\underline{s_{\\lambda}}] \\right\\}\n\\end{align}\n\\] where the posterior distribution of \\(\\lambda\\) is inverse gamma 2 distribution: \\[\n\\begin{align}\np(\\lambda|Y,X, A,\\Sigma) = \\mathcal{IG}2(\\overline{s_{\\lambda}},\\overline{\\nu_{\\lambda}})\n\\end{align}\n\\] and the parameters of the posterior distribution is: \\[\n\\begin{align}\n\\overline{s_{\\lambda}} &= tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] + \\underline{s_{\\lambda}} \\\\\n\\overline{\\nu_{\\lambda}} &= \\underline{\\nu_{\\lambda}} + TN\n\\end{align}\n\\]\n\n\n4.2.3 Algorithm Validation\nTo check the validity of the algorithms, two independent bi-variate Gaussian random walk processes with 1,000 observations were generated to simulate unit-root non-stationary macroeconomic variables.\n\nGibbs Sampler\nUsing the parameter of the joint posterior distribution \\(\\overline{A}\\), \\(\\overline{V}\\),\\(\\overline{S}\\), \\(\\overline{\\nu}\\) in the section 4.2.2, we obtain a sample of \\(S\\) draws from the posterior distribution.\nInitialise \\(\\lambda\\) at \\(\\lambda^{(0)}\\).\nAt each iteration \\(s\\) where \\(s\\) goes from 1 to \\(S\\),\n\nDraw \\(\\Sigma^{(s)} \\sim P(\\Sigma|Y,X,\\lambda^{(s-1)})\\) from the \\(\\mathcal{IW}_N(\\overline{S},\\overline{\\nu})\\) distribution using \\(\\lambda^{(s-1)}\\). For \\(s\\) = 1, use the initialised value \\(\\lambda^{(0)}\\).\nDraw \\(A^{(s)} \\sim P(A|Y,X,\\Sigma^{(s)},\\lambda^{(s-1)})\\) from the \\(\\mathcal{MN}_{K \\times N}(\\overline{A},\\Sigma^{(s)}, \\overline{V})\\) distribution using the draws \\(\\Sigma^{(s)}\\) and \\(\\lambda^{(s-1)}\\).\nDraw \\(\\lambda^{(s)} \\sim P(\\lambda|Y,X,A^{(s)},\\Sigma^{(s)})\\) from \\(\\mathcal{IG}2(\\overline{S_{\\lambda}},\\overline{\\nu_{\\lambda}})\\) distribution using the draws \\(A^{(s)}\\) and \\(\\Sigma^{(s)}\\).\n\nOutput is the sample draws from the joint posterior distribution \\(\\left\\{ {A^{(s)}, \\Sigma^{(s)}} ,\\lambda^{(s)}\\right\\}^{S}_{s=1}\\).\nApplying same method as 4.1.3, except for applying the function extended.posterior below to compute posterior distribution for t-distributed error model.\n\n\nSee R code\nextended.posterior &lt;- function(X, Y, N, p, S, prior.distribution) {\n  \n  A.prior  &lt;- prior.distribution$A.prior\n  V.prior  &lt;- prior.distribution$V.prior\n  S.prior  &lt;- prior.distribution$S.prior\n  nu.prior &lt;- prior.distribution$nu.prior\n  s.prior.lambda   &lt;- 5    # assume that it is fixed\n  nu.prior.lambda  &lt;- 5    # assume that it is fixed\n  lambda   &lt;- s.prior.lambda/rchisq(1, nu.prior.lambda)\n  \n  # Posterior distribution\n  ############################################################\n  # Initialise arrays to store posterior draws\n  Sigma.posterior   &lt;- array(NA, c(N,N,S))\n  A.posterior       &lt;- array(NA, c(K,N,S))\n  lambda.posterior  &lt;- rep(NA, S)\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    \n    # Specify the matrix normal-inverse Wishart posterior parameters\n    # ----------------------------------------------------------\n    V.bar.inv  &lt;- t(X)%*%X/lambda + diag(1/diag(V.prior))\n    V.bar      &lt;- solve(V.bar.inv)\n    A.bar      &lt;- V.bar%*%(t(X)%*%Y/lambda + diag(1/diag(V.prior))%*%A.prior)\n    nu.bar     &lt;- nrow(Y) + nu.prior\n    S.bar      &lt;- S.prior + t(Y)%*%Y/lambda + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv  &lt;- solve(S.bar)\n    \n    # Draw Posterior distribution\n    # ----------------------------------------------------------\n    ## Draw from the Reduced Form\n    ### Draw Sigma from the inverse Wishart distribution\n    Sigma.posterior.inv   &lt;- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]\n    Sigma.posterior[,,s]  &lt;- solve(Sigma.posterior.inv)\n    \n    ### Draw A from matrix-variate normal distribution\n    A.posterior[,,s]      &lt;- matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior[,,s]%x%V.bar), ncol=N)\n    \n    ### Draw lambda from inverse gamma 2 distribution\n    s.posterior.lambda    &lt;- sum(diag(Sigma.posterior.inv%*%t(Y-X%*%A.posterior[,,s])%*%(Y-X%*%A.posterior[,,s]))) + s.prior.lambda\n    nu.posterior.lambda   &lt;- nrow(Y)*ncol(Y) + nu.prior.lambda\n    lambda                &lt;- s.posterior.lambda/rchisq(1, nu.posterior.lambda)\n    lambda.posterior[s]   &lt;- lambda\n    \n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s           &lt;- chol(Sigma.posterior[,,s])\n    B0.posterior[,,s]     &lt;- solve(t(cholSigma.s)) \n    \n    ### Draw Bplus\n    B1.posterior[,,s]     &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n  }\n  \n  return(list(B0.posterior = B0.posterior, \n              B1.posterior = B1.posterior,\n              A.posterior = A.posterior, \n              Sigma.posterior = Sigma.posterior,\n              lambda.posterior = lambda.posterior))\n}\n\n\nThe results below show the mean of the matrices \\(B_0\\) and \\(B_+\\).\n\n\nMean of \\(B_0\\) Matrix\n\n\n0.9095\n0.0106\n\n\n0.0108\n0.9206\n\n\n\n\n\n\nMean of \\(B_+\\) Matrix\n\n\n0.0477\n0.9040\n0.0115\n\n\n0.0169\n0.0176\n0.9156\n\n\n\n\nThe results below show the mean of the matrices \\(A\\) and \\(\\Sigma\\).\n\n\nMean of the \\(A\\) posterior\n\n\n\ny1\ny2\n\n\n\n\nconstant\n0.0518\n0.0156\n\n\nlag of y1\n0.9940\n0.0076\n\n\nlag of y2\n0.0010\n0.9946\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\n\ny1\ny2\n\n\n\n\ny1\n0.5588\n-0.0062\n\n\ny2\n-0.0062\n0.5462\n\n\n\n\nThe lambda value below verifies that the main diagonal of sigma is equal to 1 if multiply it with lambda.\n\n\nMean of the \\(\\lambda\\) posterior\n\n\nlambda\n\n\n\n\n2.012"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-stochastic-volatility",
    "href": "index.html#bayesian-svar-model-with-stochastic-volatility",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.3 Bayesian SVAR Model with Stochastic Volatility",
    "text": "4.3 Bayesian SVAR Model with Stochastic Volatility\n\n4.3.1 Model Specification\nThe reduced form representation in a matrix form is as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim \\mathcal{MN}_{T \\times N}(0_{T \\times N},\\Sigma,\\text{diag}(\\sigma^2))\n\\end{gather}\n\\] where the column-specific covariance matrix of error terms is set to be \\(\\text{diag}(\\sigma^2)\\).\nThe parameter \\(\\sigma^2\\) is a vector of conditional heteroskedasticity variables:\n\n\n4.3.2 Estimation Procedure\nThen we have the likelihood function as: \\[\n\\begin{gather}\nL(A,\\Sigma|Y,X,\\sigma^2) \\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'\\text{diag}(\\sigma^2)^{-1}(Y-XA) \\right] \\right\\} \\\\\n\\end{gather}\n\\]\nThe conditional posterior distribution of \\(A\\) and \\(\\Sigma\\) is given by the product of the likelihood function and the prior distribution. \\[\n\\begin{align}\np(A,\\Sigma|Y,X,\\sigma^2) &\\propto L(A,\\Sigma|Y,X,\\sigma^2) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X,\\sigma^2) \\cdot p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'\\text{diag}(\\sigma^2)^{-1}(Y-XA) \\right] \\right\\}\n\\\\ &\\quad\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'\\text{diag}(\\sigma^2)^{-1}X(A-\\hat{A}) \\right] \\right\\} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'\\text{diag}(\\sigma^2)^{-1}(Y-X \\hat{A}) \\right] \\right\\}\n\\\\ &\\quad\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1} \\left[(A-\\hat{A})'X'\\text{diag}(\\sigma^2)^{-1}X(A-\\hat{A})+(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})+(Y-X\\hat{A})'\\text{diag}(\\sigma^2)^{-1}(Y-X\\hat{A})+\\underline{S} \\right] \\right] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'\\text{diag}(\\sigma^2)^{-1}Y - 2A'X'\\text{diag}(\\sigma^2)^{-1}Y + A'X'\\text{diag}(\\sigma^2)^{-1}XA + A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})] \\right\\}\n\\end{align}\n\\]\nThe full conditional posterior of \\((A,\\Sigma)\\) would follow a \\(MNIW(\\bar{A},\\bar{V},\\bar{S},\\bar{\\nu})\\) distribution. \\[\n\\begin{gather}\np(A,\\Sigma|X,Y,\\sigma^2) \\propto L(A,\\Sigma|Y,X,\\sigma^2) \\times  p(A|\\Sigma) \\times p(\\Sigma)\n\\end{gather}\n\\] with parameters: \\[\n\\begin{align}\n\\overline{V} &= (X'\\text{diag}(\\sigma^2)^{-1}X + \\underline{V}^{-1})^{-1}\n\\\\ \\overline{A} &= \\overline{V}(X'\\text{diag}(\\sigma^2)^{-1}Y + \\underline{V}^{-1}\\underline{A})\n\\\\ \\overline{S} &= \\underline{S} + Y'\\text{diag}(\\sigma^2)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A}\n\\\\ \\overline{\\nu} &= \\underline{\\nu} + T\n\\end{align}\n\\]\n\n\n4.3.3 Algorithm\n\nGibbs Sampler\nThe function SVcommon.Gibbs.iteration below computes Gibbs sampler for the stochastic volatility.\n\n\nSee R code\nSVcommon.Gibbs.iteration &lt;- function(aux, priors) {\n  # A single iteration of the Gibbs sampler for the SV component\n  #\n  # aux is a list containing:\n  #   Y        - a TxN matrix\n  #   X        - a TxK matrix\n  #   H        - a Tx1 matrix\n  #   h0       - a scalar\n  #   sigma.v2 - a scalar\n  #   s        - a Tx1 matrix\n  #   A        - a KxN matrix\n  #   Sigma    - an NxN matrix\n  #   sigma2   - a Tx1 matrix\n  #\n  # priors is a list containing:\n  #   h0.v      - a positive scalar\n  #   h0.m      - a scalar\n  #   sigmav.s  - a positive scalar\n  #   sigmav.nu - a positive scalar\n  #   HH        - a TxT matrix\n  \n  T             &lt;- dim(aux$Y)[1]\n  N             &lt;- dim(aux$Y)[2]\n  alpha.st      &lt;- c(1.92677,1.34744,0.73504,0.02266,0-0.85173,-1.97278,-3.46788,-5.55246,-8.68384,-14.65000)\n  sigma.st      &lt;- c(0.11265,0.17788,0.26768,0.40611,0.62699,0.98583,1.57469,2.54498,4.16591,7.33342)\n  pi.st         &lt;- c(0.00609,0.04775,0.13057,0.20674,0.22715,0.18842,0.12047,0.05591,0.01575,0.00115)\n  \n  Lambda        &lt;- solve(chol(aux$Sigma))\n  Z             &lt;- rowSums( ( aux$Y - aux$X %*% aux$A ) %*% Lambda ) / sqrt(N)\n  Y.tilde       &lt;- as.vector(log((Z + 0.0000001)^2))\n  Ytilde.alpha  &lt;- as.matrix(Y.tilde - alpha.st[as.vector(aux$s)])\n  \n  # sampling initial condition\n  ############################################################\n  V.h0.bar      &lt;- 1/((1/priors$h0.v) + (1/aux$sigma.v2))\n  m.h0.bar      &lt;- V.h0.bar*((priors$h0.m/priors$h0.v) + (aux$H[1]/aux$sigma.v2))\n  h0.draw       &lt;- rnorm(1, mean = m.h0.bar, sd = sqrt(V.h0.bar))\n  aux$h0        &lt;- h0.draw\n  \n  # sampling sigma.v2\n  ############################################################\n  sigma.v2.s    &lt;- priors$sigmav.s + sum(c(aux$H[1] - aux$h0, diff(aux$H))^2)\n  sigma.v2.draw &lt;- sigma.v2.s/rchisq(1,priors$sigmav.nu + T)\n  aux$sigma.v2  &lt;- sigma.v2.draw\n  \n  # sampling auxiliary states\n  ############################################################\n  Pr.tmp        &lt;- simplify2array(lapply(1:10,function(x){\n    dnorm(Y.tilde, mean = as.vector(aux$H+alpha.st[x]), sd=sqrt(sigma.st[x]), log=TRUE) + log(pi.st[x])\n  }))\n  Pr            &lt;- t(apply(Pr.tmp, 1, function(x){exp(x-max(x))/sum(exp(x-max(x)))}))\n  s.cum         &lt;- t(apply(Pr,1,cumsum))\n  r             &lt;- matrix(rep(runif(T),10), ncol = 10)\n  ss            &lt;- apply(s.cum&lt;r, 1, sum) + 1\n  aux$s         &lt;- as.matrix(ss)\n\n  # sampling log-volatilities using functions for tridiagonal precision matrix\n  ############################################################\n  Sigma.s.inv   &lt;- diag(1/sigma.st[as.vector(aux$s)])\n  D.inv         &lt;- Sigma.s.inv + (1/aux$sigma.v2)*priors$HH\n  b             &lt;- as.matrix(Ytilde.alpha/sigma.st[as.vector(aux$s)] + (aux$h0/aux$sigma.v2)*diag(T)[,1])\n  lead.diag     &lt;- diag(D.inv)\n  sub.diag      &lt;- mgcv::sdiag(D.inv,-1)\n  D.chol        &lt;- mgcv::trichol(ld=lead.diag, sd=sub.diag)\n  D.L           &lt;- diag(D.chol$ld)\n  mgcv::sdiag(D.L,-1) &lt;- D.chol$sd\n  x             &lt;- as.matrix(rnorm(T))\n  a             &lt;- forwardsolve(D.L,b)\n  draw          &lt;- backsolve(t(D.L),a+x)\n  aux$H         &lt;- as.matrix(draw)\n  aux$sigma2    &lt;- as.matrix(exp(draw))\n  \n  return(aux)\n}\n\n\nThe function SV.baseline.posterior below computes posterior distribution of the standard model with stochastic volatility.\n\n\nSee R code\nSV.baseline.posterior &lt;- function(Y, X, S, prior.distribution) {\n  \n  N &lt;- ncol(Y)\n  K &lt;- ncol(X)\n  T &lt;- nrow(Y)\n \n  A.prior &lt;- prior.distribution$A.prior\n  V.prior &lt;- prior.distribution$V.prior\n  S.prior &lt;- prior.distribution$S.prior\n  nu.prior &lt;- prior.distribution$nu.prior\n\n  Sigma.posterior   &lt;- array(NA, c(N,N,S))\n  A.posterior       &lt;- array(NA, c(K,N,S))\n  H.posterior       &lt;- array(NA,c(T, S+1))\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  # Initialise h0\n  H.posterior[,1]     &lt;- matrix(1, T, 1) \n  HH                  &lt;- 2*diag(T)\n  mgcv::sdiag(HH, -1) &lt;- -1\n  mgcv::sdiag(HH, 1)  &lt;- -1\n  nu.bar              &lt;- nrow(Y) + nu.prior\n  \n  # Define priors for the SV model\n  priors = list(HH = HH,\n                h0.m = 0,\n                h0.v = 1,\n                sigmav.s = 1,\n                sigmav.nu = 1)\n  \n  for (s in 1:S){\n    \n    # Posterior distribution\n    ############################################################\n    # Specify the matrix normal-inverse Wishart posterior parameters\n    # ----------------------------------------------------------\n    V.bar.inv   &lt;- t(X)%*%diag(1/H.posterior[,s])%*%X + diag(1/diag(V.prior))\n    V.bar       &lt;- solve(V.bar.inv)\n    A.bar       &lt;- V.bar%*%(t(X)%*%diag(1/H.posterior[,s])%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    S.bar       &lt;- S.prior + t(Y)%*%diag(1/H.posterior[,s])%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior-t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv   &lt;- solve(S.bar)\n    \n    # Draw Posterior distribution\n    # ----------------------------------------------------------\n    ## Draw from the Reduced Form\n    ### Draw Sigma from the inverse Wishart distribution\n    Sigma.posterior.inv   &lt;- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]\n    Sigma.posterior[,,s]  &lt;- solve(Sigma.posterior.inv)\n    \n    ### Draw A from matrix-variate normal distribution\n    A.posterior[,,s]      &lt;- matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior[,,s]%x%V.bar), ncol=N)\n    \n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s           &lt;- chol(Sigma.posterior[,,s])\n    B0.posterior[,,s]     &lt;- solve(t(cholSigma.s)) \n    \n    ### Draw Bplus\n    B1.posterior[,,s]     &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n    \n    ## Draw H from SVcommon.Gibbs.iteration function\n    if (s == 1){  # initialise input arguments \n        aux = list( \n              Y             = Y,\n              X             = X,\n              H             = matrix(1,T,1),\n              h0            = 0,\n              sigma.v2      = 1,\n              s             = matrix(1,T,1),\n              Sigma         = Sigma.posterior[,,s],\n              A             = A.posterior[,,s],\n              sigma2        = matrix(1,T,1))\n        \n    }else{  # update input arguments  \n      aux = list(\n                Y           = Y,\n                X           = X,\n                H           = tmp$H,\n                h0          = tmp$h0,\n                sigma.v2    = tmp$sigma.v2,\n                s           = tmp$s,\n                Sigma       = Sigma.posterior[,,s],\n                A           = A.posterior[,,s],\n                sigma2      = tmp$sigma2)\n      }\n    \n    tmp &lt;- SVcommon.Gibbs.iteration(aux, priors)\n    H.posterior[,s+1] &lt;- as.matrix(tmp$sigma2)\n    }\n  \n  return(list(Sigma.posterior = Sigma.posterior[,,2:S], \n              A.posterior = A.posterior[,,2:S], \n              B1.posterior = B1.posterior[,,2:S], \n              B0.posterior = B0.posterior[,,2:S], \n              H.posterior = H.posterior[,3:S+1]))\n  }\n\n\nThe results below show the mean of the matrices \\(B_0\\) and \\(B_+\\).\n\n\nMean of \\(B_0\\) Matrix\n\n\n14.3165\n0.7070\n\n\n2.0641\n14.8465\n\n\n\n\n\n\nMean of \\(B_+\\) Matrix\n\n\n1.5418\n14.0999\n0.7843\n\n\n-0.2967\n2.2675\n14.6986\n\n\n\n\nThe results below show the mean of the matrices \\(A\\) and \\(\\Sigma\\).\n\n\n\nMean of the \\(A\\) posterior\n\n\n\ny1\ny2\n\n\n\n\nconstant\n0.1092\n-0.0396\n\n\nlag of y1\n0.9845\n0.0160\n\n\nlag of y2\n0.0054\n0.9893\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\n\ny1\ny2\n\n\n\n\ny1\n0.0258\n-0.0007\n\n\ny2\n-0.0007\n0.0249\n\n\n\n\nFigure 5 provides a time series plot of posterior mean of \\(\\sigma^2\\). \\(\\sigma^2\\) oscillates around the value of 2100 over time.\n\n\n\n\n\n\n\nFigure 5: Plot of posterior mean of stochastic volatility (standard model with stochastic volatility)"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-errors-and-stochastic-volatility",
    "href": "index.html#bayesian-svar-model-with-t-distributed-errors-and-stochastic-volatility",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.4 Bayesian SVAR Model with t-distributed Errors and Stochastic Volatility",
    "text": "4.4 Bayesian SVAR Model with t-distributed Errors and Stochastic Volatility\n\n4.4.1 Model Specification\nThe reduced form representation in a matrix form is as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X,\\lambda \\sim \\mathcal{MN}_{T \\times N}(0_{T \\times N},\\Sigma,\\lambda\\text{diag}(\\sigma^2))\n\\end{gather}\n\\] where the column-specific covariance matrix of error terms is set to be \\(\\lambda \\text{diag}(\\sigma^2)\\).\nThe parameter lambda is inverse gamma 2 distributed with scale parameter \\(s_{\\lambda}\\) and shape parameter \\(\\nu_{\\lambda}\\). We assume fixed numbers for \\(s_{\\lambda}\\) and \\(\\nu_{\\lambda}\\) in this study. \\[\n\\lambda \\sim \\mathcal{IG}2(s_{\\lambda}, \\nu_{\\lambda})\n\\]\n\n\n4.4.2 Estimation Procedure\nThen we have the likelihood function as: \\[\n\\begin{gather}\nL(A,\\Sigma|Y,X,\\sigma^2, \\lambda) \\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda \\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(\\lambda \\text{diag}(\\sigma^2))^{-1}(Y-XA) \\right] \\right\\} \\\\\n\\end{gather}\n\\]\nApplying the same calculation procedure from the section 4.2.2, \\[\n\\begin{align}\np(A,\\Sigma|Y,X,\\sigma^2,\\lambda) &\\propto L(A,\\Sigma|Y,X,\\sigma^2,\\lambda) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X,\\sigma^2,\\lambda) \\cdot p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda\\text{diag}(\\sigma^2))^{-1} (Y-XA) ] \\right\\}\n\\\\ &\\quad\\times\n\\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp \\left\\{ -\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1} \\left[(A-\\hat{A})'X'(\\lambda\\text{diag}(\\sigma^2))^{-1}X(A-\\hat{A})+(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})+(Y-X\\hat{A})'(\\lambda\\text{diag}(\\sigma^2))^{-1}(Y-X\\hat{A})+\\underline{S} \\right] \\right] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\lambda\\text{diag}(\\sigma^2))^{-\\frac{N}{2}}\n\\\\ &\\quad\\times \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda\\text{diag}(\\sigma^2))^{-1}Y - 2A'X'(\\lambda\\text{diag}(\\sigma^2))^{-1}Y + A'X'(\\lambda\\text{diag}(\\sigma^2))^{-1}XA + A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})] \\right\\}\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\overline{V} &= (X'(\\lambda\\text{diag}(\\sigma^2))^{-1}X + \\underline{V}^{-1})^{-1}\n\\\\ \\overline{A} &= \\overline{V}(X'(\\lambda\\text{diag}(\\sigma^2))^{-1}Y + \\underline{V}^{-1}\\underline{A})\n\\\\ \\overline{S} &= \\underline{S} + Y'(\\lambda\\text{diag}(\\sigma^2))^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A}\n\\\\ \\overline{\\nu} &= T + \\underline{\\nu}\n\\end{align}\n\\] The conditional posterior distribution of \\(\\lambda\\) is derived as follows: \\[\n\\begin{align}\np(\\lambda|Y,X,A,\\Sigma,\\sigma^2) &\\propto L(A,\\Sigma|Y,X,\\sigma^2,\\lambda) \\cdot p(\\lambda) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda \\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda \\text{diag}(\\sigma^2))^{-1} (Y-XA)] \\right\\}\n\\\\ &\\quad\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} tr[\\Sigma^{-1}(Y-XA)' \\text{diag}(\\sigma^2)^{-1} (Y-XA)] \\right\\} \\\\\n&\\quad\\times \\lambda^{-\\frac{TN}{2}} \\cdot \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} \\cdot \\lambda^{-\\frac{TN+\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} [tr(\\Sigma^{-1}(Y-XA)' \\text{diag}(\\sigma^2)^{-1} (Y-XA)) + \\underline{s_{\\lambda}}] \\right\\}\n\\end{align}\n\\] \\[\n\\begin{align}\np(\\lambda|Y,X,A,\\Sigma,\\sigma^2) = \\mathcal{IG}2(\\overline{s_{\\lambda}},\\overline{\\nu_{\\lambda}})\n\\end{align}\n\\] and the parameters of the posterior distribution is: \\[\n\\begin{align}\n\\overline{s_{\\lambda}} &= tr[\\Sigma^{-1}(Y-XA)' \\text{diag}(\\sigma^2)^{-1} (Y-XA)] + \\underline{s_{\\lambda}} \\\\\n\\overline{\\nu_{\\lambda}} &= \\underline{\\nu_{\\lambda}} + TN\n\\end{align}\n\\]\n\n\n4.4.3 Algorithm\n\nGibbs Sampler\nUsing the parameter of the joint posterior distribution \\(\\overline{A}\\), \\(\\overline{V}\\),\\(\\overline{S}\\), \\(\\overline{\\nu}\\) above, we obtain a sample of \\(S\\) draws from the posterior distribution.\nInitialise \\(h\\) at \\(h_t^{(0)}\\) and \\(\\lambda\\) at \\(\\lambda^{(0)}\\).\nAt each iteration \\(s\\) where \\(s\\) goes from 1 to \\(S\\),\n\nDraw \\(\\Sigma^{(s)} \\sim P(\\Sigma|Y,X,\\sigma^{2(s-1)},\\lambda^{(s-1)})\\) from the \\(\\mathcal{IW}_N(\\overline{S},\\overline{\\nu})\\) distribution using \\(\\sigma^{2(s-1)}\\) and \\(\\lambda^{(s-1)}\\). For \\(s\\) = 1, use the initialised value \\(h_t^{(0)}\\) and \\(\\lambda^{(0)}\\).\nDraw \\(A^{(s)} \\sim P(A|Y,X,\\Sigma^{(s)},\\sigma^{2(s-1)},\\lambda^{(s-1)})\\) from the \\(\\mathcal{MN}_{K \\times N}(\\overline{A},\\Sigma^{(s)}, \\overline{V})\\) distribution using the draws \\(\\Sigma^{(s)}\\), \\(\\sigma^{2(s-1)}\\) and \\(\\lambda^{(s-1)}\\).\nDraw \\(\\lambda^{(s)} \\sim P(\\lambda|Y,X,A^{(s)},\\Sigma^{(s)},\\sigma^{2(s-1)})\\) from \\(\\mathcal{IG}2(\\overline{S_{\\lambda}},\\overline{\\nu_{\\lambda}})\\) distribution using the draws \\(A^{(s)}\\), \\(\\Sigma^{(s)}\\) and \\(\\sigma^{2(s-1)}\\).\nDraw \\(h_t^{(0)}\\).\n\nOutput is the sample draws from the joint posterior distribution \\(\\left\\{ {A^{(s)}, \\Sigma^{(s)}} , \\sigma^{2(s)} , \\lambda^{(s)}\\right\\}^{S}_{s=1}\\).\nThe function SV.extended.posterior below computes posterior distribution of the t-distributed error model with stochastic volatility.\n\n\nSee R code\nSV.extended.posterior &lt;- function(Y, X, S, prior.distribution) {\n  \n  N &lt;- ncol(Y)\n  K &lt;- ncol(X)\n  T &lt;- nrow(Y)\n  \n  A.prior &lt;- prior.distribution$A.prior\n  V.prior &lt;- prior.distribution$V.prior\n  S.prior &lt;- prior.distribution$S.prior\n  nu.prior &lt;- prior.distribution$nu.prior\n  s.prior.lambda   &lt;- 5    # assume that it is fixed\n  nu.prior.lambda  &lt;- 5    # assume that it is fixed\n  lambda   &lt;- s.prior.lambda/rchisq(1, nu.prior.lambda)\n\n  Sigma.posterior   &lt;- array(NA, c(N,N,S))\n  A.posterior       &lt;- array(NA, c(K,N,S))\n  H.posterior       &lt;- array(NA, c(T, S+1))\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  # Initialise h0\n  H.posterior[,1]     &lt;- matrix(1, T, 1) \n  HH                  &lt;- 2*diag(T)\n  mgcv::sdiag(HH, -1) &lt;- -1\n  mgcv::sdiag(HH, 1)  &lt;- -1\n  nu.bar              &lt;- nrow(Y) + nu.prior\n  \n  # Define priors for the SV model\n  priors = list(HH = HH,\n                h0.m = 0,\n                h0.v = 1,\n                sigmav.s = 1,\n                sigmav.nu = 1)\n  \n  for (s in 1:S) {\n    \n    # Posterior distribution\n    ############################################################\n    # Specify the matrix normal-inverse Wishart posterior parameters\n    # ----------------------------------------------------------\n    V.bar.inv   &lt;- t(X)%*%diag(1/H.posterior[,s])%*%X + diag(1/diag(V.prior))\n    V.bar       &lt;- solve(V.bar.inv)\n    A.bar       &lt;- V.bar%*%(t(X)%*%diag(1/H.posterior[,s])%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    S.bar       &lt;- S.prior + t(Y)%*%diag(1/H.posterior[,s])%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior-t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv   &lt;- solve(S.bar)\n    \n    # Draw Posterior distribution\n    # ----------------------------------------------------------\n    ## Draw from the Reduced Form\n    ### Draw Sigma from the inverse Wishart distribution\n    Sigma.posterior.inv   &lt;- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]\n    Sigma.posterior[,,s]  &lt;- solve(Sigma.posterior.inv)\n    \n    ### Draw A from matrix-variate normal distribution\n    A.posterior[,,s]      &lt;- matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior[,,s]%x%V.bar), ncol=N)\n    \n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s           &lt;- chol(Sigma.posterior[,,s])\n    B0.posterior[,,s]     &lt;- solve(t(cholSigma.s)) \n    \n    ### Draw Bplus\n    B1.posterior[,,s]     &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n    \n    ## Draw H from SVcommon.Gibbs.iteration function\n    if (s == 1){  # initialise input arguments \n        aux = list( \n              Y             = Y,\n              X             = X,\n              H             = matrix(1,T,1),\n              h0            = 0,\n              sigma.v2      = 1,\n              s             = matrix(1,T,1),\n              Sigma         = Sigma.posterior[,,s],\n              A             = A.posterior[,,s],\n              sigma2        = matrix(1,T,1))\n        \n    }else{  # update input arguments  \n      aux = list(\n                Y           = Y,\n                X           = X,\n                H           = tmp$H,\n                h0          = tmp$h0,\n                sigma.v2    = tmp$sigma.v2,\n                s           = tmp$s,\n                Sigma       = Sigma.posterior[,,s],\n                A           = A.posterior[,,s],\n                sigma2      = tmp$sigma2)\n      }\n    \n    tmp &lt;- SVcommon.Gibbs.iteration(aux, priors)\n    H.posterior[, s + 1] &lt;- as.matrix(tmp$sigma2)\n    }\n  \n  return(list(Sigma.posterior = Sigma.posterior[,,2:S], \n              A.posterior = A.posterior[,,2:S], \n              B1.posterior = B1.posterior[,,2:S], \n              B0.posterior = B0.posterior[,,2:S], \n              H.posterior = H.posterior[,3:S+1]))\n  }\n\n\n\n\nMean of \\(B_0\\) Matrix\n\n\n14.3395\n0.5895\n\n\n2.0592\n14.8471\n\n\n\n\n\n\nMean of \\(B_+\\) Matrix\n\n\n1.5864\n14.1255\n0.6601\n\n\n-0.4303\n2.2666\n14.6988\n\n\n\n\nThe results below show the mean of the matrices \\(A\\) and \\(\\Sigma\\).\n\n\n\nMean of the \\(A\\) posterior\n\n\n\ny1\ny2\n\n\n\n\nconstant\n0.1092\n-0.0404\n\n\nlag of y1\n0.9845\n0.0159\n\n\nlag of y2\n0.0054\n0.9894\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\n\ny1\ny2\n\n\n\n\ny1\n0.0262\n-0.0009\n\n\ny2\n-0.0009\n0.0259\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Plot of posterior mean of stochastic volatility (t-distributed error model with stochastic volatility)"
  },
  {
    "objectID": "index.html#standard-bayesian-svar-model-1",
    "href": "index.html#standard-bayesian-svar-model-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.1 Standard Bayesian SVAR model",
    "text": "5.1 Standard Bayesian SVAR model\nThe result below shows the mean of \\(B_0\\) inverse matrix. The sign restrictions imposed in the second column is shown in the table.\n\n\nMean of \\(B_0\\) inverse Matrix\n\n\n0e+00\n-0.0033\n0e+00\n0e+00\n0.0000\n0e+00\n\n\n-9e-04\n0.0999\n3e-04\n-1e-04\n0.0026\n6e-04\n\n\n0e+00\n-0.0017\n1e-04\n0e+00\n0.0000\n0e+00\n\n\n-2e-04\n0.0119\n0e+00\n0e+00\n0.0003\n-1e-04\n\n\n0e+00\n0.0039\n2e-04\n2e-04\n0.0000\n-1e-04\n\n\n0e+00\n-0.0269\n-3e-04\n6e-04\n-0.0003\n1e-03\n\n\n\n\n\n\n\nMean of the \\(A\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n0.0799\n1.9850\n0.0070\n0.0816\n0.1230\n-3.9366\n\n\n0.9905\n-0.1831\n-0.0010\n0.0054\n0.0269\n-0.4945\n\n\n-0.0026\n1.4587\n0.0041\n-0.0003\n0.0029\n-0.0561\n\n\n-0.0059\n-0.1977\n0.9991\n-0.0036\n0.0093\n-0.3338\n\n\n0.0015\n0.0592\n-0.0026\n0.9833\n-0.0076\n0.2035\n\n\n0.0027\n0.1646\n0.0017\n0.0032\n0.9802\n0.6977\n\n\n-0.0044\n-0.0693\n-0.0006\n-0.0033\n-0.0213\n0.4604\n\n\n-0.0019\n-0.0466\n-0.0001\n0.0017\n0.0072\n-0.1271\n\n\n0.0025\n-0.4611\n-0.0032\n-0.0052\n-0.0164\n0.0115\n\n\n-0.0013\n-0.0564\n-0.0003\n0.0000\n0.0038\n-0.0909\n\n\n0.0010\n-0.0636\n-0.0006\n-0.0140\n-0.0077\n0.0872\n\n\n0.0013\n-0.0023\n0.0005\n-0.0064\n-0.0217\n0.1758\n\n\n0.0025\n0.1017\n0.0012\n0.0067\n0.0118\n0.0915\n\n\n-0.0007\n-0.0253\n0.0000\n0.0008\n0.0033\n-0.0606\n\n\n0.0001\n-0.0762\n-0.0005\n0.0045\n0.0069\n-0.0016\n\n\n-0.0004\n-0.0276\n-0.0001\n0.0003\n0.0019\n-0.0375\n\n\n0.0004\n-0.0477\n-0.0001\n-0.0066\n-0.0018\n0.0321\n\n\n0.0006\n-0.0123\n0.0001\n-0.0014\n-0.0093\n0.0580\n\n\n0.0014\n-0.0430\n-0.0002\n0.0012\n0.0002\n0.0994\n\n\n-0.0003\n-0.0165\n0.0000\n0.0007\n0.0021\n-0.0281\n\n\n-0.0011\n0.0089\n-0.0002\n0.0006\n0.0038\n0.0701\n\n\n-0.0002\n-0.0138\n-0.0001\n0.0003\n0.0012\n-0.0226\n\n\n0.0000\n-0.0226\n0.0000\n-0.0034\n0.0012\n0.0230\n\n\n0.0002\n-0.0096\n0.0002\n-0.0003\n-0.0038\n0.0276\n\n\n0.0005\n-0.0152\n0.0007\n0.0047\n-0.0018\n-0.0494\n\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n1e-04\n0.0003\n0e+00\n0.0000\n0.0001\n-0.0005\n\n\n3e-04\n0.0922\n4e-04\n0.0043\n0.0019\n-0.0034\n\n\n0e+00\n0.0004\n0e+00\n0.0000\n0.0000\n-0.0003\n\n\n0e+00\n0.0043\n0e+00\n0.0012\n0.0009\n-0.0066\n\n\n1e-04\n0.0019\n0e+00\n0.0009\n0.0027\n-0.0155\n\n\n-5e-04\n-0.0034\n-3e-04\n-0.0066\n-0.0155\n0.3215\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Trace plot of \\(A\\) and \\(\\Sigma\\) posterior draws (Standard model)\n\n\n\n\nImpulse response functions of the baseline model show a positive monetary policy shock on variables. The shaded area represents 68% of the credibility interval. In the short run, GDP decreases gradually, but a year after the shock, GDP decreases at a steeper rate. In the short run, interest rates immediately respond to the shock and normalised after five years of the shock. The consumer price index slightly decreases in the short run. The exchange rate has a positive effect in the short and long run. The stock price has a positive impact in the short run, but it does not have a positive effect in the long run. GDP is the only variable that is statistically different from zero.\n\n\n\n\n\n\n\nFigure 8: Plot of impulse response functions to monetary policy shock (Standard model)"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-errors-1",
    "href": "index.html#bayesian-svar-model-with-t-distributed-errors-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.2 Bayesian SVAR Model with t-distributed Errors",
    "text": "5.2 Bayesian SVAR Model with t-distributed Errors\n\n\nMean of \\(B_0\\) inverse Matrix\n\n\n-0.0009\n-0.0033\n-0.0007\n-0.0006\n0.0015\n0.0001\n\n\n0.0250\n0.0660\n-0.0753\n-0.0654\n0.1633\n0.0232\n\n\n-0.0007\n-0.0020\n-0.0019\n0.0004\n0.0013\n0.0005\n\n\n0.0023\n0.0137\n0.0029\n0.0015\n0.0068\n0.0019\n\n\n-0.0212\n0.0209\n0.0103\n-0.0022\n0.0118\n0.0016\n\n\n0.0561\n-0.1495\n-0.0985\n0.0707\n0.0330\n-0.1792\n\n\n\n\n\n\n\nMean of the \\(A\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n0.0966\n2.5974\n-0.0027\n0.0417\n0.1590\n-3.7606\n\n\n0.9891\n-0.3213\n-0.0033\n-0.0063\n0.0337\n-0.7252\n\n\n-0.0034\n1.4675\n0.0048\n-0.0006\n0.0083\n-0.0325\n\n\n-0.0024\n0.0101\n1.0039\n0.0148\n0.0050\n-0.2930\n\n\n0.0046\n0.0043\n-0.0047\n0.9851\n-0.0063\n-0.0579\n\n\n0.0015\n0.0728\n0.0017\n0.0158\n0.9989\n0.6468\n\n\n-0.0037\n-0.0676\n-0.0010\n-0.0044\n-0.0194\n0.4653\n\n\n-0.0010\n-0.1192\n-0.0002\n-0.0036\n-0.0046\n0.0200\n\n\n0.0026\n-0.5024\n-0.0037\n-0.0118\n-0.0277\n-0.0249\n\n\n0.0013\n0.0772\n0.0006\n-0.0007\n-0.0090\n0.0680\n\n\n0.0022\n-0.0511\n0.0006\n-0.0117\n0.0127\n-0.0177\n\n\n-0.0011\n-0.0704\n-0.0006\n-0.0023\n-0.0213\n0.1406\n\n\n0.0029\n0.1187\n0.0013\n0.0049\n0.0110\n0.1330\n\n\n-0.0024\n0.0351\n0.0000\n0.0021\n-0.0012\n0.0764\n\n\n0.0008\n-0.0563\n-0.0007\n0.0115\n0.0137\n-0.0220\n\n\n-0.0022\n-0.0161\n0.0003\n0.0050\n0.0103\n-0.1998\n\n\n-0.0018\n-0.1133\n-0.0007\n-0.0117\n-0.0089\n0.0416\n\n\n0.0003\n-0.0368\n0.0009\n-0.0102\n-0.0110\n0.0378\n\n\n0.0004\n-0.1030\n-0.0002\n-0.0012\n-0.0019\n0.0744\n\n\n0.0005\n-0.0801\n-0.0009\n0.0001\n-0.0047\n0.0819\n\n\n-0.0015\n0.0141\n0.0000\n0.0012\n0.0039\n0.0883\n\n\n-0.0011\n-0.0015\n-0.0008\n-0.0031\n-0.0041\n0.0555\n\n\n0.0003\n0.0610\n0.0005\n0.0005\n0.0002\n0.1424\n\n\n0.0011\n0.0755\n0.0009\n-0.0041\n-0.0093\n-0.0098\n\n\n0.0004\n0.0490\n0.0008\n0.0081\n-0.0021\n-0.0238\n\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n1e-04\n0.0003\n0e+00\n0.0000\n0.0001\n-0.0003\n\n\n3e-04\n0.0982\n4e-04\n0.0041\n0.0009\n0.0101\n\n\n0e+00\n0.0004\n0e+00\n0.0000\n0.0001\n-0.0004\n\n\n0e+00\n0.0041\n0e+00\n0.0012\n0.0008\n-0.0058\n\n\n1e-04\n0.0009\n1e-04\n0.0008\n0.0028\n-0.0154\n\n\n-3e-04\n0.0101\n-4e-04\n-0.0058\n-0.0154\n0.3472\n\n\n\n\n\n\n\nImpulse response functions of the t-distributed innovation model show a positive monetary policy shock on variables. In the short run, interest rates immediately respond to the shock and normalise after five years. The consumer price index slightly decreases in the short run. There are no significant effects on GDP, stock prices, or stock price volatility. Consumer price index and exchange rates decrease slightly but are also insignificant. GDP is the only variable that is statistically different from zero. Note that the shaded area represents 68% credibility interval.\n\n\n\n\n\n\n\nFigure 9: Plot of impulse response functions to monetary policy shock (t-distributed error model)"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-stochastic-volatility-1",
    "href": "index.html#bayesian-svar-model-with-stochastic-volatility-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.3 Bayesian SVAR Model with Stochastic Volatility",
    "text": "5.3 Bayesian SVAR Model with Stochastic Volatility\nThe result below shows the mean of \\(B_0\\) inverse matrix. The sign restrictions imposed in the second column is shown in the table.\n\n\nMean of \\(B_0\\) inverse Matrix\n\n\n0e+00\n-0.0004\n0e+00\n0e+00\n0e+00\n0e+00\n\n\n-1e-04\n0.0163\n-3e-04\n-4e-04\n-3e-04\n0e+00\n\n\n0e+00\n-0.0002\n0e+00\n0e+00\n0e+00\n0e+00\n\n\n0e+00\n0.0019\n0e+00\n0e+00\n0e+00\n0e+00\n\n\n0e+00\n0.0005\n1e-04\n0e+00\n0e+00\n0e+00\n\n\n-1e-04\n-0.0096\n-1e-03\n1e-04\n6e-04\n-1e-04\n\n\n\n\n\n\n\nMean of the \\(A\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n0.0129\n-0.0448\n-0.0023\n0.0111\n0.0469\n-1.0797\n\n\n0.9997\n-0.0063\n0.0002\n0.0010\n0.0010\n-0.0525\n\n\n-0.0002\n1.0675\n0.0007\n0.0012\n-0.0028\n-0.0122\n\n\n-0.0004\n-0.0064\n1.0002\n0.0004\n-0.0005\n-0.0365\n\n\n-0.0001\n-0.0075\n0.0000\n0.9982\n0.0000\n0.0133\n\n\n0.0000\n0.0253\n0.0005\n0.0001\n0.9960\n0.0170\n\n\n0.0003\n-0.0016\n0.0003\n0.0041\n-0.0021\n0.6665\n\n\n-0.0001\n-0.0020\n0.0001\n0.0002\n0.0003\n-0.0134\n\n\n0.0002\n-0.0363\n-0.0002\n0.0004\n0.0010\n0.0083\n\n\n-0.0001\n-0.0024\n0.0001\n0.0001\n0.0000\n-0.0110\n\n\n0.0000\n-0.0034\n0.0000\n-0.0006\n0.0000\n0.0029\n\n\n0.0000\n0.0071\n0.0001\n0.0000\n-0.0013\n-0.0021\n\n\n-0.0002\n0.0076\n-0.0001\n0.0002\n0.0027\n-0.0044\n\n\n0.0000\n-0.0012\n0.0000\n0.0001\n0.0001\n-0.0059\n\n\n0.0002\n-0.0295\n-0.0002\n0.0001\n0.0010\n0.0017\n\n\n0.0000\n-0.0013\n0.0000\n0.0001\n0.0000\n-0.0044\n\n\n0.0000\n-0.0026\n0.0000\n-0.0003\n0.0001\n0.0009\n\n\n0.0000\n0.0023\n0.0000\n0.0002\n-0.0004\n-0.0028\n\n\n0.0001\n0.0012\n0.0000\n0.0010\n-0.0010\n0.0236\n\n\n0.0000\n-0.0004\n0.0000\n0.0001\n0.0000\n-0.0026\n\n\n0.0002\n-0.0220\n-0.0002\n-0.0002\n0.0006\n0.0036\n\n\n0.0000\n-0.0008\n0.0000\n0.0000\n0.0000\n-0.0023\n\n\n0.0000\n-0.0017\n0.0000\n-0.0002\n0.0001\n0.0010\n\n\n0.0000\n0.0004\n0.0000\n0.0001\n-0.0002\n-0.0016\n\n\n0.0000\n0.0039\n0.0001\n0.0007\n-0.0010\n-0.0069\n\n\n\n\n\n\n\n\n\n\nMean of the \\(\\Sigma\\) posterior\n\n\ngdp\nICR\ncpi\nEXR\nstp\nvol\n\n\n\n\n0\n0.0000\n0\n0e+00\n0e+00\n0.0000\n\n\n0\n0.0032\n0\n0e+00\n-1e-04\n0.0007\n\n\n0\n0.0000\n0\n0e+00\n0e+00\n0.0000\n\n\n0\n0.0000\n0\n0e+00\n0e+00\n-0.0002\n\n\n0\n-0.0001\n0\n0e+00\n1e-04\n-0.0006\n\n\n0\n0.0007\n0\n-2e-04\n-6e-04\n0.0167\n\n\n\n\n\n\n\nImpulse response functions of the standard model with stochastic volatility show a positive monetary policy shock on variables. In the short run, GDP and stock price volatility immediately respond to the shock and normalise within a year. No variables are statistically different from zero. Note that the shaded area represents 68% credibility interval.\n\n\n\n\n\n\n\nFigure 10: Plot of impulse response functions to monetary policy shock (Standard model with Stochastic Volatility)"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-errors-and-stochastic-volatility-1",
    "href": "index.html#bayesian-svar-model-with-t-distributed-errors-and-stochastic-volatility-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.4 Bayesian SVAR Model with t-distributed Errors and Stochastic Volatility",
    "text": "5.4 Bayesian SVAR Model with t-distributed Errors and Stochastic Volatility"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "References",
    "text": "References"
  }
]